{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q peft transformers datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\nfrom peft import get_peft_config, get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType, PeftType\nimport torch\nfrom datasets import load_dataset\nimport os\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\ndevice = \"cuda\"\nmodel_name_or_path = \"bigscience/bloomz-560m\"\ntokenizer_name_or_path = \"bigscience/bloomz-560m\"\npeft_config = PromptTuningConfig(\n    task_type=TaskType.CAUSAL_LM,\n    prompt_tuning_init=PromptTuningInit.TEXT,\n    num_virtual_tokens=8,\n    prompt_tuning_init_text=\"Classify if the tweet is a complaint or not:\",\n    tokenizer_name_or_path=model_name_or_path,\n)\n\ndataset_name = \"twitter_complaints\"\ncheckpoint_name = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}_v1.pt\".replace(\n    \"/\", \"_\"\n)\ntext_column = \"Tweet text\"\nlabel_column = \"text_label\"\nmax_length = 64\nlr = 3e-2\nnum_epochs = 50\nbatch_size = 8","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:45:48.995381Z","iopub.execute_input":"2024-02-22T03:45:48.995758Z","iopub.status.idle":"2024-02-22T03:45:49.003786Z","shell.execute_reply.started":"2024-02-22T03:45:48.995726Z","shell.execute_reply":"2024-02-22T03:45:49.002628Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(\"ought/raft\", dataset_name)\ndataset[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:45:49.225054Z","iopub.execute_input":"2024-02-22T03:45:49.225781Z","iopub.status.idle":"2024-02-22T03:45:49.979719Z","shell.execute_reply.started":"2024-02-22T03:45:49.225738Z","shell.execute_reply":"2024-02-22T03:45:49.978782Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"debaddca332143e493e095b4e3b90834"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'Tweet text': '@HMRCcustomers No this is my first job', 'ID': 0, 'Label': 2}"},"metadata":{}}]},{"cell_type":"code","source":"classes = [k.replace(\"_\", \" \") for k in dataset[\"train\"].features[\"Label\"].names]\ndataset = dataset.map(\n    lambda x: {\"text_label\": [classes[label] for label in x[\"Label\"]]},\n    batched=True,\n    num_proc=1,\n)\ndataset[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:45:49.981332Z","iopub.execute_input":"2024-02-22T03:45:49.981620Z","iopub.status.idle":"2024-02-22T03:45:50.048770Z","shell.execute_reply.started":"2024-02-22T03:45:49.981596Z","shell.execute_reply":"2024-02-22T03:45:50.047930Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c25402637434426a4ad108fc8869a4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a702b9152d84ee3aafbc9a8f6ba8952"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'Tweet text': '@HMRCcustomers No this is my first job',\n 'ID': 0,\n 'Label': 2,\n 'text_label': 'no complaint'}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\nif tokenizer.pad_token_id is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id\ntarget_max_length = max([len(tokenizer(class_label)[\"input_ids\"]) for class_label in classes])\nprint(target_max_length)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:45:50.049844Z","iopub.execute_input":"2024-02-22T03:45:50.050127Z","iopub.status.idle":"2024-02-22T03:45:50.998883Z","shell.execute_reply.started":"2024-02-22T03:45:50.050103Z","shell.execute_reply":"2024-02-22T03:45:50.997893Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"3\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    batch_size = len(examples[text_column])\n    inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n    targets = [str(x) for x in examples[label_column]]\n    model_inputs = tokenizer(inputs)\n    labels = tokenizer(targets)\n    for i in range(batch_size):\n        sample_input_ids = model_inputs[\"input_ids\"][i]\n        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.pad_token_id]\n        # print(i, sample_input_ids, label_input_ids)\n        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n    # print(model_inputs)\n    for i in range(batch_size):\n        sample_input_ids = model_inputs[\"input_ids\"][i]\n        label_input_ids = labels[\"input_ids\"][i]\n        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n            max_length - len(sample_input_ids)\n        ) + sample_input_ids\n        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n            \"attention_mask\"\n        ][i]\n        labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n        labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:45:51.001181Z","iopub.execute_input":"2024-02-22T03:45:51.001498Z","iopub.status.idle":"2024-02-22T03:45:51.012565Z","shell.execute_reply.started":"2024-02-22T03:45:51.001473Z","shell.execute_reply":"2024-02-22T03:45:51.011605Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"processed_datasets = dataset.map(\n    preprocess_function,\n    batched=True,\n    num_proc=1,\n    remove_columns=dataset[\"train\"].column_names,\n    load_from_cache_file=False,\n    desc=\"Running tokenizer on dataset\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:45:51.013826Z","iopub.execute_input":"2024-02-22T03:45:51.014113Z","iopub.status.idle":"2024-02-22T03:45:51.892504Z","shell.execute_reply.started":"2024-02-22T03:45:51.014088Z","shell.execute_reply":"2024-02-22T03:45:51.891681Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72463f34f59d4f9c92abf7cfda53a315"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset:   0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"995edbf57d3d46c4af9bd802c0659720"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = processed_datasets[\"train\"]\neval_dataset = processed_datasets[\"test\"]\n\n\ntrain_dataloader = DataLoader(\n    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n)\neval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:45:51.893803Z","iopub.execute_input":"2024-02-22T03:45:51.894102Z","iopub.status.idle":"2024-02-22T03:45:51.899625Z","shell.execute_reply.started":"2024-02-22T03:45:51.894077Z","shell.execute_reply":"2024-02-22T03:45:51.898576Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\nmodel = get_peft_model(model, peft_config)\nprint(model.print_trainable_parameters())","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:45:53.136816Z","iopub.execute_input":"2024-02-22T03:45:53.137207Z","iopub.status.idle":"2024-02-22T03:45:57.725718Z","shell.execute_reply.started":"2024-02-22T03:45:53.137178Z","shell.execute_reply":"2024-02-22T03:45:57.724712Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"trainable params: 8,192 || all params: 559,222,784 || trainable%: 0.0014648902430985358\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\nlr_scheduler = get_linear_schedule_with_warmup(\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=(len(train_dataloader) * num_epochs),\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:46:00.012300Z","iopub.execute_input":"2024-02-22T03:46:00.013095Z","iopub.status.idle":"2024-02-22T03:46:00.021172Z","shell.execute_reply.started":"2024-02-22T03:46:00.013060Z","shell.execute_reply":"2024-02-22T03:46:00.020152Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model = model.to(device)\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    for step, batch in enumerate(tqdm(train_dataloader)):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        total_loss += loss.detach().float()\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n\n    model.eval()\n    eval_loss = 0\n    eval_preds = []\n    for step, batch in enumerate(tqdm(eval_dataloader)):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        with torch.no_grad():\n            outputs = model(**batch)\n        loss = outputs.loss\n        eval_loss += loss.detach().float()\n        eval_preds.extend(\n            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n        )\n\n    eval_epoch_loss = eval_loss / len(eval_dataloader)\n    eval_ppl = torch.exp(eval_epoch_loss)\n    train_epoch_loss = total_loss / len(train_dataloader)\n    train_ppl = torch.exp(train_epoch_loss)\n    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:47:18.070122Z","iopub.execute_input":"2024-02-22T03:47:18.070525Z","iopub.status.idle":"2024-02-22T04:33:51.798632Z","shell.execute_reply.started":"2024-02-22T03:47:18.070494Z","shell.execute_reply":"2024-02-22T04:33:51.797710Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.41it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=0: train_ppl=tensor(1046.5624, device='cuda:0') train_epoch_loss=tensor(6.9533, device='cuda:0') eval_ppl=tensor(3409.0623, device='cuda:0') eval_epoch_loss=tensor(8.1342, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=1: train_ppl=tensor(255.4648, device='cuda:0') train_epoch_loss=tensor(5.5431, device='cuda:0') eval_ppl=tensor(5251.0288, device='cuda:0') eval_epoch_loss=tensor(8.5662, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=2: train_ppl=tensor(150.7249, device='cuda:0') train_epoch_loss=tensor(5.0155, device='cuda:0') eval_ppl=tensor(6107.8960, device='cuda:0') eval_epoch_loss=tensor(8.7173, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=3: train_ppl=tensor(108.6954, device='cuda:0') train_epoch_loss=tensor(4.6885, device='cuda:0') eval_ppl=tensor(6382.1973, device='cuda:0') eval_epoch_loss=tensor(8.7613, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=4: train_ppl=tensor(68.4341, device='cuda:0') train_epoch_loss=tensor(4.2259, device='cuda:0') eval_ppl=tensor(8745.1025, device='cuda:0') eval_epoch_loss=tensor(9.0762, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=5: train_ppl=tensor(52.3024, device='cuda:0') train_epoch_loss=tensor(3.9570, device='cuda:0') eval_ppl=tensor(10650.6729, device='cuda:0') eval_epoch_loss=tensor(9.2734, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=6: train_ppl=tensor(38.3367, device='cuda:0') train_epoch_loss=tensor(3.6464, device='cuda:0') eval_ppl=tensor(10771.3086, device='cuda:0') eval_epoch_loss=tensor(9.2846, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=7: train_ppl=tensor(26.7002, device='cuda:0') train_epoch_loss=tensor(3.2847, device='cuda:0') eval_ppl=tensor(14994.9248, device='cuda:0') eval_epoch_loss=tensor(9.6155, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=8: train_ppl=tensor(20.7391, device='cuda:0') train_epoch_loss=tensor(3.0320, device='cuda:0') eval_ppl=tensor(14255.7373, device='cuda:0') eval_epoch_loss=tensor(9.5649, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=9: train_ppl=tensor(15.3345, device='cuda:0') train_epoch_loss=tensor(2.7301, device='cuda:0') eval_ppl=tensor(20439.2402, device='cuda:0') eval_epoch_loss=tensor(9.9252, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=10: train_ppl=tensor(12.9376, device='cuda:0') train_epoch_loss=tensor(2.5601, device='cuda:0') eval_ppl=tensor(17724.0156, device='cuda:0') eval_epoch_loss=tensor(9.7827, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.45it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=11: train_ppl=tensor(8.8105, device='cuda:0') train_epoch_loss=tensor(2.1759, device='cuda:0') eval_ppl=tensor(20710.2305, device='cuda:0') eval_epoch_loss=tensor(9.9384, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=12: train_ppl=tensor(6.5182, device='cuda:0') train_epoch_loss=tensor(1.8746, device='cuda:0') eval_ppl=tensor(23848.3574, device='cuda:0') eval_epoch_loss=tensor(10.0795, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=13: train_ppl=tensor(4.6741, device='cuda:0') train_epoch_loss=tensor(1.5420, device='cuda:0') eval_ppl=tensor(30760.1641, device='cuda:0') eval_epoch_loss=tensor(10.3340, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=14: train_ppl=tensor(3.8220, device='cuda:0') train_epoch_loss=tensor(1.3408, device='cuda:0') eval_ppl=tensor(62567.2227, device='cuda:0') eval_epoch_loss=tensor(11.0440, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.45it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=15: train_ppl=tensor(3.3986, device='cuda:0') train_epoch_loss=tensor(1.2234, device='cuda:0') eval_ppl=tensor(20823.4941, device='cuda:0') eval_epoch_loss=tensor(9.9438, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=16: train_ppl=tensor(2.3932, device='cuda:0') train_epoch_loss=tensor(0.8726, device='cuda:0') eval_ppl=tensor(37325.6602, device='cuda:0') eval_epoch_loss=tensor(10.5274, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=17: train_ppl=tensor(1.9151, device='cuda:0') train_epoch_loss=tensor(0.6498, device='cuda:0') eval_ppl=tensor(29211.3438, device='cuda:0') eval_epoch_loss=tensor(10.2823, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=18: train_ppl=tensor(1.6532, device='cuda:0') train_epoch_loss=tensor(0.5027, device='cuda:0') eval_ppl=tensor(43852.2148, device='cuda:0') eval_epoch_loss=tensor(10.6886, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=19: train_ppl=tensor(1.5679, device='cuda:0') train_epoch_loss=tensor(0.4497, device='cuda:0') eval_ppl=tensor(40863.4531, device='cuda:0') eval_epoch_loss=tensor(10.6180, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=20: train_ppl=tensor(1.5219, device='cuda:0') train_epoch_loss=tensor(0.4200, device='cuda:0') eval_ppl=tensor(47956.3516, device='cuda:0') eval_epoch_loss=tensor(10.7780, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=21: train_ppl=tensor(1.4184, device='cuda:0') train_epoch_loss=tensor(0.3495, device='cuda:0') eval_ppl=tensor(41109.3203, device='cuda:0') eval_epoch_loss=tensor(10.6240, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=22: train_ppl=tensor(1.3994, device='cuda:0') train_epoch_loss=tensor(0.3361, device='cuda:0') eval_ppl=tensor(29990.8066, device='cuda:0') eval_epoch_loss=tensor(10.3086, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=23: train_ppl=tensor(1.4214, device='cuda:0') train_epoch_loss=tensor(0.3516, device='cuda:0') eval_ppl=tensor(14398.3535, device='cuda:0') eval_epoch_loss=tensor(9.5749, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=24: train_ppl=tensor(1.3371, device='cuda:0') train_epoch_loss=tensor(0.2905, device='cuda:0') eval_ppl=tensor(25226.2910, device='cuda:0') eval_epoch_loss=tensor(10.1356, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.45it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=25: train_ppl=tensor(1.2766, device='cuda:0') train_epoch_loss=tensor(0.2442, device='cuda:0') eval_ppl=tensor(39548.9961, device='cuda:0') eval_epoch_loss=tensor(10.5853, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=26: train_ppl=tensor(1.3006, device='cuda:0') train_epoch_loss=tensor(0.2629, device='cuda:0') eval_ppl=tensor(26639.2441, device='cuda:0') eval_epoch_loss=tensor(10.1901, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=27: train_ppl=tensor(1.3143, device='cuda:0') train_epoch_loss=tensor(0.2733, device='cuda:0') eval_ppl=tensor(30446.4512, device='cuda:0') eval_epoch_loss=tensor(10.3237, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=28: train_ppl=tensor(1.2394, device='cuda:0') train_epoch_loss=tensor(0.2146, device='cuda:0') eval_ppl=tensor(30902.0918, device='cuda:0') eval_epoch_loss=tensor(10.3386, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=29: train_ppl=tensor(1.2411, device='cuda:0') train_epoch_loss=tensor(0.2160, device='cuda:0') eval_ppl=tensor(20697.1191, device='cuda:0') eval_epoch_loss=tensor(9.9377, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=30: train_ppl=tensor(1.2786, device='cuda:0') train_epoch_loss=tensor(0.2457, device='cuda:0') eval_ppl=tensor(27755.1426, device='cuda:0') eval_epoch_loss=tensor(10.2312, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=31: train_ppl=tensor(1.2523, device='cuda:0') train_epoch_loss=tensor(0.2250, device='cuda:0') eval_ppl=tensor(23677.3730, device='cuda:0') eval_epoch_loss=tensor(10.0723, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=32: train_ppl=tensor(1.1824, device='cuda:0') train_epoch_loss=tensor(0.1675, device='cuda:0') eval_ppl=tensor(57942.9727, device='cuda:0') eval_epoch_loss=tensor(10.9672, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=33: train_ppl=tensor(1.2001, device='cuda:0') train_epoch_loss=tensor(0.1824, device='cuda:0') eval_ppl=tensor(22458.6914, device='cuda:0') eval_epoch_loss=tensor(10.0194, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=34: train_ppl=tensor(1.1753, device='cuda:0') train_epoch_loss=tensor(0.1615, device='cuda:0') eval_ppl=tensor(35827.0977, device='cuda:0') eval_epoch_loss=tensor(10.4865, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=35: train_ppl=tensor(1.1870, device='cuda:0') train_epoch_loss=tensor(0.1714, device='cuda:0') eval_ppl=tensor(54694.0195, device='cuda:0') eval_epoch_loss=tensor(10.9095, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=36: train_ppl=tensor(1.1739, device='cuda:0') train_epoch_loss=tensor(0.1603, device='cuda:0') eval_ppl=tensor(34728.2891, device='cuda:0') eval_epoch_loss=tensor(10.4553, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=37: train_ppl=tensor(1.2082, device='cuda:0') train_epoch_loss=tensor(0.1891, device='cuda:0') eval_ppl=tensor(46126.4805, device='cuda:0') eval_epoch_loss=tensor(10.7391, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=38: train_ppl=tensor(1.1943, device='cuda:0') train_epoch_loss=tensor(0.1776, device='cuda:0') eval_ppl=tensor(37885.1172, device='cuda:0') eval_epoch_loss=tensor(10.5423, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=39: train_ppl=tensor(1.1581, device='cuda:0') train_epoch_loss=tensor(0.1468, device='cuda:0') eval_ppl=tensor(55388.7383, device='cuda:0') eval_epoch_loss=tensor(10.9221, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=40: train_ppl=tensor(1.1311, device='cuda:0') train_epoch_loss=tensor(0.1232, device='cuda:0') eval_ppl=tensor(86235.1250, device='cuda:0') eval_epoch_loss=tensor(11.3648, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=41: train_ppl=tensor(1.1312, device='cuda:0') train_epoch_loss=tensor(0.1233, device='cuda:0') eval_ppl=tensor(99748.9922, device='cuda:0') eval_epoch_loss=tensor(11.5104, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=42: train_ppl=tensor(1.1333, device='cuda:0') train_epoch_loss=tensor(0.1251, device='cuda:0') eval_ppl=tensor(78669.6094, device='cuda:0') eval_epoch_loss=tensor(11.2730, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=43: train_ppl=tensor(1.1563, device='cuda:0') train_epoch_loss=tensor(0.1452, device='cuda:0') eval_ppl=tensor(75490.6328, device='cuda:0') eval_epoch_loss=tensor(11.2318, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=44: train_ppl=tensor(1.1575, device='cuda:0') train_epoch_loss=tensor(0.1463, device='cuda:0') eval_ppl=tensor(66169.7344, device='cuda:0') eval_epoch_loss=tensor(11.1000, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=45: train_ppl=tensor(1.1727, device='cuda:0') train_epoch_loss=tensor(0.1593, device='cuda:0') eval_ppl=tensor(73045.6016, device='cuda:0') eval_epoch_loss=tensor(11.1988, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=46: train_ppl=tensor(1.1098, device='cuda:0') train_epoch_loss=tensor(0.1042, device='cuda:0') eval_ppl=tensor(66024.4375, device='cuda:0') eval_epoch_loss=tensor(11.0978, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=47: train_ppl=tensor(1.1126, device='cuda:0') train_epoch_loss=tensor(0.1067, device='cuda:0') eval_ppl=tensor(73729.0234, device='cuda:0') eval_epoch_loss=tensor(11.2082, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.46it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch=48: train_ppl=tensor(1.1222, device='cuda:0') train_epoch_loss=tensor(0.1153, device='cuda:0') eval_ppl=tensor(75047.0234, device='cuda:0') eval_epoch_loss=tensor(11.2259, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  4.47it/s]\n100%|██████████| 425/425 [00:54<00:00,  7.83it/s]","output_type":"stream"},{"name":"stdout","text":"epoch=49: train_ppl=tensor(1.1150, device='cuda:0') train_epoch_loss=tensor(0.1089, device='cuda:0') eval_ppl=tensor(75047.0234, device='cuda:0') eval_epoch_loss=tensor(11.2259, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T03:46:57.078737Z","iopub.execute_input":"2024-02-22T03:46:57.079114Z","iopub.status.idle":"2024-02-22T03:46:57.105192Z","shell.execute_reply.started":"2024-02-22T03:46:57.079084Z","shell.execute_reply":"2024-02-22T03:46:57.104268Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a2ececc69014f87ba08a928c4af066b"}},"metadata":{}}]},{"cell_type":"code","source":"peft_model_id = \"likhith231/bloomz-560m_PROMPT_TUNING_CAUSAL_LM_50\"\nmodel.push_to_hub(\"likhith231/bloomz-560m_PROMPT_TUNING_CAUSAL_LM_50\", use_auth_token=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T04:33:51.800260Z","iopub.execute_input":"2024-02-22T04:33:51.801082Z","iopub.status.idle":"2024-02-22T04:33:53.539570Z","shell.execute_reply.started":"2024-02-22T04:33:51.801043Z","shell.execute_reply":"2024-02-22T04:33:53.538737Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:821: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/32.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e47d9080433494aa4d35d0411f50e1a"}},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/likhith231/bloomz-560m_PROMPT_TUNING_CAUSAL_LM_50/commit/296795ece4345723b7f06531034b68d094b3a8fa', commit_message='Upload model', commit_description='', oid='296795ece4345723b7f06531034b68d094b3a8fa', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"i=10\nf'{text_column} : {dataset[\"test\"][i][\"Tweet text\"]} Label : '\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T04:40:10.021698Z","iopub.execute_input":"2024-02-22T04:40:10.022335Z","iopub.status.idle":"2024-02-22T04:40:10.028994Z","shell.execute_reply.started":"2024-02-22T04:40:10.022302Z","shell.execute_reply":"2024-02-22T04:40:10.027974Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'Tweet text : @BTCare Yes but was cut off. Can someone come out? Label : '"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import AutoPeftModelForCausalLM\nfrom transformers import AutoTokenizer\n\n\nmodel = AutoPeftModelForCausalLM.from_pretrained(\"likhith231/bloomz-560m_PROMPT_TUNING_CAUSAL_LM_50\").to(\"cuda\")\ntokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloomz-560m\")\n\ninputs = tokenizer(\n    \"Tweet text : Couples wallpaper, so cute. :) #BrothersAtHome. Label : \",\n    return_tensors=\"pt\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T04:41:07.172426Z","iopub.execute_input":"2024-02-22T04:41:07.173129Z","iopub.status.idle":"2024-02-22T04:41:12.622484Z","shell.execute_reply.started":"2024-02-22T04:41:07.173097Z","shell.execute_reply":"2024-02-22T04:41:12.621621Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"import torch\nwith torch.no_grad():\n    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n    outputs = model.generate(\n        input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_new_tokens=10, eos_token_id=3\n    )\n    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-02-22T04:41:12.623957Z","iopub.execute_input":"2024-02-22T04:41:12.624223Z","iopub.status.idle":"2024-02-22T04:41:12.700990Z","shell.execute_reply.started":"2024-02-22T04:41:12.624200Z","shell.execute_reply":"2024-02-22T04:41:12.700103Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"['Tweet text : Couples wallpaper, so cute. :) #BrothersAtHome. Label : no complaint']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}